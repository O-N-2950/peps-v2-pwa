"""
Routes API pour l'IA Coach Gemini Flash
Fournit des suggestions intelligentes pour aider les partenaires √† am√©liorer leur business
"""

from flask import Blueprint, jsonify, request
from flask_jwt_extended import jwt_required, get_jwt_identity
from models import db, User, Partner, Offer, PrivilegeUsage
from datetime import datetime, timedelta
import os
import json
import time

# ============================================
# CONFIGURATION GEMINI (Google SDK)
# ============================================

try:
    import google.generativeai as genai
    GEMINI_SDK_AVAILABLE = True
except ImportError:
    GEMINI_SDK_AVAILABLE = False
    print("[AI_COACH] ‚ö†Ô∏è google-generativeai non install√©. Ex√©cutez: pip install google-generativeai")

GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')

if not GOOGLE_API_KEY:
    print("[AI_COACH] ‚ö†Ô∏è ERREUR CRITIQUE: GOOGLE_API_KEY manquante !")
    print("[AI_COACH] Ajoutez-la sur Railway : Variables ‚Üí GOOGLE_API_KEY=AIzaSy...")
    print("[AI_COACH] Obtenez votre cl√© sur : https://aistudio.google.com/apikey")
else:
    print(f"[AI_COACH] ‚úÖ Cl√© Google API configur√©e (commence par {GOOGLE_API_KEY[:10]}...)")
    if GEMINI_SDK_AVAILABLE:
        genai.configure(api_key=GOOGLE_API_KEY)

# ============================================
# CHARGEMENT DU PROMPT SYST√àME
# ============================================

DEFAULT_PROMPT = """Tu es Pepi, l'assistant virtuel intelligent de PEP's (Privil√®ges √âconomiques et Partenariats).

PEP's est une plateforme suisse qui connecte des membres avec des commer√ßants partenaires offrant des privil√®ges exclusifs.

Ton r√¥le :
- R√©pondre aux questions sur PEP's
- Aider √† trouver des partenaires par cat√©gorie ou localisation
- Conseiller les commer√ßants partenaires sur les privil√®ges attractifs
- √ätre chaleureux, professionnel et pr√©cis

R√©ponds toujours en fran√ßais de Suisse."""

# Priorit√© 1 : Variable d'environnement Railway
PEPI_SYSTEM_PROMPT = os.environ.get('PEPI_SYSTEM_PROMPT')

if PEPI_SYSTEM_PROMPT:
    print(f"[AI_COACH] ‚úÖ Prompt Pepi charg√© depuis variable d'environnement ({len(PEPI_SYSTEM_PROMPT)} caract√®res)")
else:
    # Priorit√© 2 : Fichier local (d√©veloppement)
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    PEPI_PROMPT_PATH = os.path.join(BASE_DIR, 'PEPI_PROMPT.md')
    try:
        with open(PEPI_PROMPT_PATH, 'r', encoding='utf-8') as f:
            PEPI_SYSTEM_PROMPT = f.read()
        print(f"[AI_COACH] ‚úÖ Prompt Pepi charg√© depuis fichier: {PEPI_PROMPT_PATH} ({len(PEPI_SYSTEM_PROMPT)} caract√®res)")
    except Exception as e:
        print(f"[AI_COACH] ‚ö†Ô∏è Fichier prompt introuvable, utilisation du fallback: {e}")
        PEPI_SYSTEM_PROMPT = DEFAULT_PROMPT

# Validation
if len(PEPI_SYSTEM_PROMPT) < 100:
    print(f"[AI_COACH] ‚ö†Ô∏è WARNING: PEPI_SYSTEM_PROMPT semble incomplet ({len(PEPI_SYSTEM_PROMPT)} caract√®res)")
else:
    print(f"[AI_COACH] ‚úÖ Prompt syst√®me valid√© : {len(PEPI_SYSTEM_PROMPT)} caract√®res")

# ============================================
# CONFIGURATION MOD√àLE GEMINI
# ============================================

generation_config = {
    "temperature": 0.7,
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 2048,
}

safety_settings = [
    {
        "category": "HARM_CATEGORY_HARASSMENT",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_HATE_SPEECH",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
        "threshold": "BLOCK_NONE"
    },
    {
        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
        "threshold": "BLOCK_NONE"
    },
]

# Initialisation du mod√®le
model = None
if GEMINI_SDK_AVAILABLE and GOOGLE_API_KEY:
    try:
        model = genai.GenerativeModel(
            model_name="gemini-2.0-flash-exp",  # Version stable recommand√©e
            generation_config=generation_config,
            safety_settings=safety_settings,
            system_instruction=PEPI_SYSTEM_PROMPT
        )
        print(f"[AI_COACH] ‚úÖ Mod√®le Gemini initialis√© : gemini-2.0-flash-exp")
    except Exception as e:
        print(f"[AI_COACH] ‚ùå Erreur initialisation mod√®le Gemini: {e}")
        model = None
else:
    print(f"[AI_COACH] ‚ùå Mod√®le Gemini non initialis√© (SDK: {GEMINI_SDK_AVAILABLE}, API Key: {bool(GOOGLE_API_KEY)})")

ai_coach_bp = Blueprint('ai_coach', __name__, url_prefix='/api/ai-coach')

def get_partner_from_token():
    """R√©cup√®re le partenaire depuis le token JWT"""
    try:
        user_id = int(get_jwt_identity()) if isinstance(get_jwt_identity(), str) else get_jwt_identity()['id']
        partner = Partner.query.filter_by(user_id=user_id).first()
        return partner
    except:
        return None

def get_partner_stats(partner):
    """R√©cup√®re les statistiques du partenaire pour l'IA"""
    now = datetime.utcnow()
    
    # Activations 7 derniers jours
    seven_days_ago = now - timedelta(days=7)
    activations_7d = PrivilegeUsage.query.join(Offer).filter(
        Offer.partner_id == partner.id,
        PrivilegeUsage.used_at >= seven_days_ago
    ).count()
    
    # Activations 30 derniers jours
    thirty_days_ago = now - timedelta(days=30)
    activations_30d = PrivilegeUsage.query.join(Offer).filter(
        Offer.partner_id == partner.id,
        PrivilegeUsage.used_at >= thirty_days_ago
    ).count()
    
    # Activations mois pr√©c√©dent (pour comparaison)
    sixty_days_ago = now - timedelta(days=60)
    activations_prev_month = PrivilegeUsage.query.join(Offer).filter(
        Offer.partner_id == partner.id,
        PrivilegeUsage.used_at >= sixty_days_ago,
        PrivilegeUsage.used_at < thirty_days_ago
    ).count()
    
    # Followers
    followers_count = len(partner.followers_list)
    
    # Derni√®re offre flash
    last_flash_offer = Offer.query.filter_by(
        partner_id=partner.id,
        offer_type='flash'
    ).order_by(Offer.created_at.desc()).first()
    
    days_since_flash = None
    if last_flash_offer and last_flash_offer.created_at:
        days_since_flash = (now - last_flash_offer.created_at).days
    
    # Nombre d'offres actives
    active_offers = Offer.query.filter_by(partner_id=partner.id, active=True).count()
    
    # Offres sans photo (si le champ image_url existe)
    offers_without_photo = Offer.query.filter_by(
        partner_id=partner.id,
        active=True
    ).filter(
        (Offer.image_url == None) | (Offer.image_url == '')
    ).count() if hasattr(Offer, 'image_url') else 0
    
    return {
        'activations_7d': activations_7d,
        'activations_30d': activations_30d,
        'activations_prev_month': activations_prev_month,
        'followers': followers_count,
        'days_since_flash': days_since_flash,
        'active_offers': active_offers,
        'offers_without_photo': offers_without_photo,
        'partner_name': partner.name,
        'partner_category': partner.category
    }

def call_gemini_flash(prompt):
    """Appelle l'API Gemini Flash pour g√©n√©rer des suggestions (pour coach partenaires)"""
    if not model:
        print("[AI_COACH] ‚ùå Mod√®le Gemini non disponible")
        return []
    
    try:
        # Cr√©er un mod√®le temporaire pour les suggestions (sans system_instruction)
        temp_model = genai.GenerativeModel(
            model_name="gemini-2.0-flash-exp",
            generation_config=generation_config,
            safety_settings=safety_settings
        )
        
        system_prompt = """Tu es un coach business expert pour les commerces partenaires PEP's.
Ta mission : analyser les donn√©es et donner 3 suggestions actionnables et concr√®tes.

Format de r√©ponse (JSON strict) :
{
  "suggestions": [
    {
      "type": "performance|followers|contenu|timing|opportunite",
      "icon": "emoji appropri√©",
      "title": "Titre court et percutant",
      "description": "Explication claire (max 80 caract√®res)",
      "action": "Texte du bouton d'action",
      "priority": "high|medium|low"
    }
  ]
}

R√®gles :
- Sois direct et actionnable
- Utilise des chiffres pr√©cis
- Propose des solutions concr√®tes
- Reste positif et encourageant
- Maximum 3 suggestions"""
        
        full_prompt = system_prompt + "\n\n" + prompt
        
        chat = temp_model.start_chat(history=[])
        response = chat.send_message(full_prompt)
        
        content = response.text
        
        # Parser la r√©ponse JSON
        try:
            # Extraire le JSON si entour√© de markdown
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()
            
            result = json.loads(content)
            return result.get('suggestions', [])
        except json.JSONDecodeError:
            # Fallback si le parsing √©choue
            return []
            
    except Exception as e:
        print(f"Erreur Gemini API: {e}")
        return []

@ai_coach_bp.route('/suggestions', methods=['GET'])
@jwt_required()
def get_suggestions():
    """G√©n√®re des suggestions IA pour le partenaire"""
    partner = get_partner_from_token()
    if not partner:
        return jsonify({'error': 'Partenaire non trouv√©'}), 404
    
    # R√©cup√©rer les stats
    stats = get_partner_stats(partner)
    
    # Construire le prompt pour Gemini
    prompt = f"""
Analyse les donn√©es de ce commerce partenaire PEP's et donne 3 suggestions pour am√©liorer sa performance :

üìä DONN√âES :
- Nom : {stats['partner_name']}
- Cat√©gorie : {stats['partner_category']}
- Activations derniers 7 jours : {stats['activations_7d']}
- Activations derniers 30 jours : {stats['activations_30d']}
- Activations mois pr√©c√©dent : {stats['activations_prev_month']}
- Followers : {stats['followers']}
- Offres actives : {stats['active_offers']}
- Jours depuis derni√®re offre flash : {stats['days_since_flash'] if stats['days_since_flash'] is not None else 'Jamais cr√©√©'}
- Offres sans photo : {stats['offers_without_photo']}

üéØ CONTEXTE :
- PEP's est une plateforme de privil√®ges pour membres
- Les offres flash g√©n√®rent du trafic imm√©diat
- Les followers re√ßoivent les notifications push
- Plus de photos = plus d'engagement

Donne 3 suggestions concr√®tes et actionnables.
"""
    
    # Appeler Gemini
    suggestions = call_gemini_flash(prompt)
    
    # Si l'IA ne r√©pond pas, utiliser des suggestions par d√©faut bas√©es sur les r√®gles
    if not suggestions:
        suggestions = generate_fallback_suggestions(stats)
    
    return jsonify({
        'suggestions': suggestions,
        'stats': stats
    })

def generate_fallback_suggestions(stats):
    """G√©n√®re des suggestions par d√©faut si l'IA ne r√©pond pas"""
    suggestions = []
    
    # R√®gle 1 : Offre flash
    if stats['days_since_flash'] is None or stats['days_since_flash'] > 10:
        suggestions.append({
            'type': 'performance',
            'icon': '‚ö°',
            'title': 'Cr√©ez une offre flash',
            'description': 'Aucune offre flash r√©cente. Boostez votre visibilit√© !',
            'action': 'Cr√©er maintenant',
            'priority': 'high'
        })
    
    # R√®gle 2 : Followers
    if stats['followers'] < 20:
        suggestions.append({
            'type': 'followers',
            'icon': 'üë•',
            'title': f'Objectif : 25 followers',
            'description': f'Vous avez {stats["followers"]} followers. Cr√©ez des offres attractives !',
            'action': 'Voir actions',
            'priority': 'medium'
        })
    
    # R√®gle 3 : Photos
    if stats['offers_without_photo'] > 0:
        suggestions.append({
            'type': 'contenu',
            'icon': 'üì∏',
            'title': 'Ajoutez des photos',
            'description': f'{stats["offers_without_photo"]} offre(s) sans photo. +40% d\'engagement !',
            'action': 'Upload photos',
            'priority': 'medium'
        })
    
    # R√®gle 4 : Performance en baisse
    if stats['activations_30d'] < stats['activations_prev_month'] * 0.7:
        suggestions.append({
            'type': 'performance',
            'icon': 'üìâ',
            'title': 'Activations en baisse',
            'description': 'Vos activations baissent. Cr√©ez une offre flash ce weekend !',
            'action': 'Cr√©er offre',
            'priority': 'high'
        })
    
    # R√®gle 5 : Encouragement
    if stats['activations_30d'] > stats['activations_prev_month']:
        suggestions.append({
            'type': 'opportunite',
            'icon': 'üéâ',
            'title': 'Excellente progression !',
            'description': f'+{int((stats["activations_30d"] - stats["activations_prev_month"]) / stats["activations_prev_month"] * 100)}% ce mois. Continuez !',
            'action': 'Voir stats',
            'priority': 'low'
        })
    
    # Retourner maximum 3 suggestions
    return suggestions[:3]

# ============================================
# ENDPOINT CHAT
# ============================================

@ai_coach_bp.route('/chat', methods=['POST'])
def chat():
    """
    Endpoint de chat avec Pepi (Gemini Flash via SDK Google)
    """
    try:
        # === VALIDATION ===
        if not GOOGLE_API_KEY:
            return jsonify({
                'error': 'Configuration serveur manquante. Contacte l\'administrateur.'
            }), 500
        
        if not model:
            return jsonify({
                'error': 'Service IA temporairement indisponible. R√©essaie dans un instant.'
            }), 500
        
        # === LOGS DE D√âMARRAGE ===
        print(f"\n{'='*60}")
        print(f"[CHAT] üöÄ Nouvelle requ√™te chat")
        print(f"[CHAT] Prompt syst√®me : {len(PEPI_SYSTEM_PROMPT)} caract√®res")
        
        data = request.get_json()
        user_message = data.get('message', '').strip()
        print(f"[CHAT] Message utilisateur : {user_message[:100]}...")
        
        if not user_message:
            return jsonify({'error': 'Message vide'}), 400
        
        # === RECHERCHE PARTENAIRES (RAG) ===
        partners_context = ""
        keywords = [
            'partenaire', 'commer√ßant', 'commerce', 'boutique', 'magasin',
            'assurance', 'restaurant', 'caf√©', 'bar', 'coiffeur', 'salon',
            'h√¥tel', 'h√©bergement', 'fitness', 'sport', 'gym', 'cin√©ma',
            'boulangerie', 'p√¢tisserie', 'pharmacie', 'm√©dical', 'sant√©',
            'garage', 'm√©canique', 'beaut√©', 'esth√©tique', 'massage',
            'bijoutier', 'bijoux', 'fleuriste', 'fleur', 'traiteur',
            'nettoyage', 'pressing', 'librairie', 'livre', 'optique',
            'lunettes', 'v√©t√©rinaire', 'animal', 'trouver', 'cherche',
            'o√π', 'localit√©', 'ville', 'r√©gion', 'pr√®s', 'proche'
        ]
        
        should_search = any(keyword in user_message.lower() for keyword in keywords)
        
        # Extraction de la ville si mentionn√©e
        city_filter = None
        cities_swiss = ['lausanne', 'gen√®ve', 'geneva', 'bern', 'berne', 'zurich', 
                        'neuch√¢tel', 'fribourg', 'sion', 'yverdon', 'montreux', 
                        'vevey', 'nyon', 'morges', 'renens', 'aigle', 'monthey',
                        'martigny', 'sierre', 'bulle', 'payerne']
        for city in cities_swiss:
            if city in user_message.lower():
                city_filter = city
                break
        
        partners = []
        if should_search:
            print(f"[CHAT] üîç Recherche partenaires d√©clench√©e")
            if city_filter:
                print(f"[CHAT] üìç Filtre ville : {city_filter}")
            
            search_term = user_message.lower()
            
            # Construction requ√™te SQL optimis√©e
            query = Partner.query.filter_by(is_active=True)
            
            # Filtre par ville si d√©tect√©
            if city_filter:
                query = query.filter(Partner.city.ilike(f'%{city_filter}%'))
            
            # Recherche full-text
            partners = query.filter(
                db.or_(
                    Partner.business_name.ilike(f'%{search_term}%'),
                    Partner.description.ilike(f'%{search_term}%'),
                    Partner.category.ilike(f'%{search_term}%'),
                    Partner.city.ilike(f'%{search_term}%'),
                    Partner.address.ilike(f'%{search_term}%')
                )
            ).limit(10).all()
            
            print(f"[CHAT] Partenaires trouv√©s : {len(partners)}")
            
            if partners:
                partners_context = f"\n\nüìã CONTEXTE PARTENAIRES DISPONIBLES ({len(partners)}) :\n"
                for idx, p in enumerate(partners, 1):
                    partners_context += f"\n{idx}. **{p.business_name}**\n"
                    partners_context += f"   Cat√©gorie : {p.category}\n"
                    if p.description:
                        desc = p.description[:150] + "..." if len(p.description) > 150 else p.description
                        partners_context += f"   Description : {desc}\n"
                    if p.city:
                        partners_context += f"   üìç Ville : {p.city}\n"
                    if p.address:
                        partners_context += f"   Adresse : {p.address}\n"
                    if p.postal_code:
                        partners_context += f"   CP : {p.postal_code}\n"
                
                partners_context += "\nüí° Utilise ces informations pour r√©pondre pr√©cis√©ment √† l'utilisateur.\n"
        
        # === CONSTRUCTION MESSAGE COMPLET ===
        full_message = user_message
        if partners_context:
            full_message += partners_context
        
        print(f"[CHAT] Message complet : {len(full_message)} caract√®res")
        print(f"[CHAT] ‚è≥ Appel Gemini en cours...")
        
        # === APPEL GEMINI ===
        start_time = time.time()
        
        chat_session = model.start_chat(history=[])
        response = chat_session.send_message(full_message)
        
        elapsed = time.time() - start_time
        print(f"[CHAT] ‚úÖ R√©ponse Gemini re√ßue en {elapsed:.2f}s")
        
        assistant_response = response.text
        print(f"[CHAT] R√©ponse : {assistant_response[:150]}...")
        print(f"{'='*60}\n")
        
        return jsonify({
            'response': assistant_response,
            'partners_found': len(partners) if should_search else 0
        }), 200
        
    except Exception as e:
        print(f"\n{'='*60}")
        print(f"[CHAT] ‚ùå ERREUR CRITIQUE")
        print(f"[CHAT] Type: {type(e).__name__}")
        print(f"[CHAT] Message: {str(e)}")
        print(f"[CHAT] Traceback complet:")
        import traceback
        traceback.print_exc()
        print(f"{'='*60}\n")
        
        # Message d'erreur user-friendly
        error_message = "D√©sol√©, je n'ai pas pu traiter ta demande. R√©essaie dans un instant."
        
        # Messages sp√©cifiques selon l'erreur
        if "API key" in str(e) or "api_key" in str(e).lower():
            error_message = "Probl√®me de configuration API. Contacte l'administrateur."
        elif "quota" in str(e).lower():
            error_message = "Service temporairement indisponible (quota d√©pass√©)."
        elif "timeout" in str(e).lower():
            error_message = "D√©lai d√©pass√©, r√©essaie dans quelques secondes."
        
        return jsonify({
            'error': error_message
        }), 500

# ============================================
# ENDPOINT HEALTH CHECK
# ============================================

@ai_coach_bp.route('/health', methods=['GET'])
def health():
    """V√©rification sant√© du service AI"""
    return jsonify({
        'status': 'ok',
        'gemini_sdk_installed': GEMINI_SDK_AVAILABLE,
        'gemini_configured': GOOGLE_API_KEY is not None,
        'model_initialized': model is not None,
        'prompt_length': len(PEPI_SYSTEM_PROMPT)
    }), 200
