"""
Routes AI Coach - Chatbot Pepi pour PEP's
"""

import os
import sys
import google.generativeai as genai
from flask import Blueprint, request, jsonify
from models import Partner, db
import time

# ============================================
# CONFIGURATION
# ============================================

ai_coach_bp = Blueprint('ai_coach', __name__)

# Variables globales (initialis√©es au premier appel)
_model = None
_pepi_prompt = None
_initialized = False

# ============================================
# FONCTION D'INITIALISATION
# ============================================

def initialize_gemini():
    """
    Initialise Gemini au premier appel (lazy initialization)
    Cette fonction est appel√©e par l'endpoint /chat
    """
    global _model, _pepi_prompt, _initialized
    
    if _initialized:
        return True
    
    try:
        # === LOG SYST√àME ===
        print("\n" + "="*60, file=sys.stderr)
        print("[AI_COACH] üöÄ INITIALISATION GEMINI", file=sys.stderr)
        print("="*60, file=sys.stderr)
        
        # === 1. V√âRIFIER CL√â API ===
        GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')
        
        if not GOOGLE_API_KEY:
            print("[AI_COACH] ‚ùå ERREUR CRITIQUE: GOOGLE_API_KEY manquante", file=sys.stderr)
            return False
        
        print(f"[AI_COACH] ‚úÖ Cl√© Google API: {GOOGLE_API_KEY[:15]}...", file=sys.stderr)
        
        # Configurer Gemini
        genai.configure(api_key=GOOGLE_API_KEY)
        print("[AI_COACH] ‚úÖ Gemini configur√©", file=sys.stderr)
        
        # === 2. CHARGER LE PROMPT ===
        # Chemin absolu depuis la racine du projet
        BASE_DIR = os.path.dirname(os.path.abspath(__file__))
        PROMPT_PATH = os.path.join(BASE_DIR, "PEPI_PROMPT.md")
        
        print(f"[AI_COACH] üìÇ Chemin prompt: {PROMPT_PATH}", file=sys.stderr)
        print(f"[AI_COACH] üìÇ R√©pertoire courant: {os.getcwd()}", file=sys.stderr)
        print(f"[AI_COACH] üìÇ __file__: {__file__}", file=sys.stderr)
        
        # V√©rifier existence
        if os.path.exists(PROMPT_PATH):
            print(f"[AI_COACH] ‚úÖ Fichier prompt trouv√©", file=sys.stderr)
            with open(PROMPT_PATH, 'r', encoding='utf-8') as f:
                _pepi_prompt = f.read()
            print(f"[AI_COACH] ‚úÖ Prompt charg√©: {len(_pepi_prompt)} caract√®res", file=sys.stderr)
        else:
            # Fallback
            print(f"[AI_COACH] ‚ö†Ô∏è FICHIER INTROUVABLE: {PROMPT_PATH}", file=sys.stderr)
            
            # Lister les fichiers du r√©pertoire pour d√©boguer
            print(f"[AI_COACH] üìÅ Contenu de {BASE_DIR}:", file=sys.stderr)
            try:
                for item in os.listdir(BASE_DIR):
                    print(f"   - {item}", file=sys.stderr)
            except Exception as e:
                print(f"[AI_COACH] ‚ùå Impossible de lister: {e}", file=sys.stderr)
            
            # Utiliser prompt par d√©faut
            _pepi_prompt = """Tu es Pepi, l'assistant virtuel intelligent de PEP's (Privil√®ges √âconomiques et Partenariats).

PEP's est une plateforme suisse qui connecte des membres avec des commer√ßants partenaires offrant des privil√®ges exclusifs.

Ton r√¥le :
- R√©pondre aux questions sur PEP's
- Aider √† trouver des partenaires par cat√©gorie ou localisation
- Conseiller les commer√ßants sur les privil√®ges attractifs
- √ätre chaleureux, professionnel et pr√©cis

R√©ponds toujours en fran√ßais de Suisse."""
            print(f"[AI_COACH] ‚ö†Ô∏è Utilisation du prompt par d√©faut: {len(_pepi_prompt)} caract√®res", file=sys.stderr)
        
        # === 3. CONFIGURATION MOD√àLE ===
        generation_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 2048,
        }
        
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        # === 4. INITIALISER MOD√àLE ===
        print("[AI_COACH] üîß Initialisation du mod√®le Gemini...", file=sys.stderr)
        
        _model = genai.GenerativeModel(
            model_name="gemini-2.0-flash",
            generation_config=generation_config,
            safety_settings=safety_settings,
            system_instruction=_pepi_prompt
        )
        
        print("[AI_COACH] ‚úÖ Mod√®le Gemini initialis√©: gemini-2.0-flash", file=sys.stderr)
        
        # === 5. TEST RAPIDE ===
        print("[AI_COACH] üß™ Test du mod√®le...", file=sys.stderr)
        test_chat = _model.start_chat(history=[])
        test_response = test_chat.send_message("R√©ponds juste 'OK'")
        print(f"[AI_COACH] ‚úÖ Test r√©ussi: {test_response.text.strip()}", file=sys.stderr)
        
        _initialized = True
        print("="*60 + "\n", file=sys.stderr)
        
        return True
        
    except Exception as e:
        print(f"\n[AI_COACH] ‚ùå ERREUR INITIALISATION", file=sys.stderr)
        print(f"[AI_COACH] Type: {type(e).__name__}", file=sys.stderr)
        print(f"[AI_COACH] Message: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        print("="*60 + "\n", file=sys.stderr)
        return False


# ============================================
# ENDPOINTS
# ============================================

@ai_coach_bp.route('/health', methods=['GET'])
def health():
    """Endpoint de sant√©"""
    # Force l'initialisation si pas encore fait
    if not _initialized:
        success = initialize_gemini()
        if not success:
            return jsonify({
                'status': 'error',
                'initialized': False,
                'message': '√âchec initialisation Gemini'
            }), 500
    
    return jsonify({
        'status': 'ok',
        'initialized': _initialized,
        'model_ready': _model is not None,
        'prompt_length': len(_pepi_prompt) if _pepi_prompt else 0
    }), 200


@ai_coach_bp.route('/chat', methods=['POST'])
def chat():
    """
    Endpoint de chat avec Pepi
    """
    try:
        # === INITIALISATION LAZY ===
        if not _initialized:
            print("[CHAT] Initialisation Gemini...", file=sys.stderr)
            success = initialize_gemini()
            if not success:
                return jsonify({
                    'error': 'Service IA temporairement indisponible'
                }), 500
        
        # === R√âCUP√âRATION MESSAGE ===
        data = request.get_json()
        user_message = data.get('message', '').strip()
        
        print(f"\n[CHAT] Message re√ßu: {user_message[:100]}...", file=sys.stderr)
        
        if not user_message:
            return jsonify({'error': 'Message vide'}), 400
        
        # === RECHERCHE PARTENAIRES (RAG) ===
        partners_context = ""
        partners = []
        keywords = [
            'partenaire', 'commer√ßant', 'commerce', 'restaurant', 'caf√©',
            'coiffeur', 'h√¥tel', 'fitness', 'cin√©ma', 'boulangerie',
            'pharmacie', 'garage', 'beaut√©', 'bijoutier', 'fleuriste',
            'trouver', 'cherche', 'o√π', 'localisation'
        ]
        
        should_search = any(keyword in user_message.lower() for keyword in keywords)
        
        if should_search:
            print(f"[CHAT] üîç Recherche partenaires...", file=sys.stderr)
            
            search_term = user_message.lower()
            partners = Partner.query.filter(
                db.or_(
                    Partner.business_name.ilike(f'%{search_term}%'),
                    Partner.description.ilike(f'%{search_term}%'),
                    Partner.category.ilike(f'%{search_term}%'),
                    Partner.city.ilike(f'%{search_term}%')
                )
            ).filter_by(is_active=True).limit(10).all()
            
            print(f"[CHAT] Partenaires trouv√©s: {len(partners)}", file=sys.stderr)
            
            if partners:
                partners_context = f"\n\nüìã PARTENAIRES DISPONIBLES ({len(partners)}) :\n"
                for idx, p in enumerate(partners, 1):
                    partners_context += f"\n{idx}. **{p.business_name}**\n"
                    partners_context += f"   Cat√©gorie: {p.category}\n"
                    if p.city:
                        partners_context += f"   Ville: {p.city}\n"
                    if p.description:
                        partners_context += f"   {p.description[:100]}...\n"
        
        # === APPEL GEMINI ===
        full_message = user_message + partners_context
        
        print(f"[CHAT] ‚è≥ Appel Gemini ({len(full_message)} caract√®res)...", file=sys.stderr)
        start_time = time.time()
        
        chat_session = _model.start_chat(history=[])
        response = chat_session.send_message(full_message)
        
        elapsed = time.time() - start_time
        print(f"[CHAT] ‚úÖ R√©ponse re√ßue en {elapsed:.2f}s", file=sys.stderr)
        print(f"[CHAT] R√©ponse: {response.text[:100]}...\n", file=sys.stderr)
        
        return jsonify({
            'response': response.text,
            'partners_found': len(partners) if should_search and partners else 0
        }), 200
        
    except Exception as e:
        print(f"\n[CHAT] ‚ùå ERREUR", file=sys.stderr)
        print(f"[CHAT] Type: {type(e).__name__}", file=sys.stderr)
        print(f"[CHAT] Message: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        
        return jsonify({
            'error': 'D√©sol√©, je n\'ai pas pu traiter ta demande. R√©essaie dans un instant.'
        }), 500
